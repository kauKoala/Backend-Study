## 1. Rate Limit란?

![image](https://github.com/user-attachments/assets/74175376-5caa-4bd1-9e5f-8decb75a9772)

클라이언트 or 서비스가 보내는 트래픽을 제어할 수 있도록 하는 기술

- 동시에 3명이 요청을 할 때, 현재 2개의 요청만 받을 수 있어서 1개의 요청은 거부 당하는 그림
- 유료 사용자는 우선 사용권을 가지게 한다는 비즈니스 로직을 추가할 수 있음
- 한 사용자가 특정 시간에 너무 많은 요청을 하게 되면 요청을 막을 수도 있음

이때 요청이 막히게 된다면 `429 Too many requests` 상태코드를 반환하게 댐

## 2. 활용 예시

### [1] 깃허브

- 엔터프라이즈 유저: 1시간에 최대 15000개 요청 가능
- 로그인 일반 유저: 1시간에 최대 5000개 요청 가능
- 미로그인 일반 유저: 공개 데이터 API 요청은 1시간에 최대 60개 가능

### [2] X (트위터)

매우 세세한 기준으로 rate limit를 적용함

window per user = 유저 1명 당 15분간 최대 요청 허용 수

![image](https://github.com/user-attachments/assets/9491fe52-5e1f-40c0-b5b2-f4df0f6055e7)

### [3] 이외에도..

- [solved.ac](http://solved.ac)는 모든 API 요청을 15분에 256회로 제한
- GPT도 요청 제한량, 속도 제한 같은 기능이 존재함

## 3. Token Bucket 알고리즘

가장 보편적인 처리율 제한 알고리즘 (Amazon, Stripe에서 사용함)

![image](https://github.com/user-attachments/assets/ecb4c5cb-e5ba-4824-a1d9-ba869ed5e233)

- 일정한 시각마다 버킷 안에 토큰이 추가되고, 요청이 들어오면 버킷 안의 토큰을 소모해 서버로 전달한다
- 버킷에 들어갈 수 있는 토큰의 최대 개수는 정해져있고, 용량을 넘어선 토큰은 버려지게 된다
- 버킷에 토큰이 남아있지 않다면 요청이 들어오면 요청이 무시된다
- 토큰 버킷 알고리즘은 하나의 API에 하나의 버킷을 두는게 일반적이다
만약 서버 전체의 처리율 제한을 적용하고 싶으면 모든 API가 버킷을 공유할 수 있다

## 4. Leaky Bucket 알고리즘

Shopify (쇼핑몰 제작 사이트)에서 사용하는 알고리즘

![image](https://github.com/user-attachments/assets/de2eb300-c285-4619-a807-c34b88c2b657)

- 요청 처리율이 고정되어 있는 알고리즘
- Token Bucket은 한 번에 트래픽이 몰려오면 남아있는 토큰의 수만큼 바로 처리할 수 있지만, Leaky Bucket 알고리즘은 처리 속도 자체가 고정되어 있다는 차이점이 존재한다
- 처리 속도가 고정되어 있기 때문에 버킷은 FIFO 구조인 큐를 사용해서 구현한다
- 큐에 요청이 모두 찼다면 이후에 요청이 들어올 경우 요청을 버리게 된다

## 5. Fixed Window Counter 알고리즘

![image](https://github.com/user-attachments/assets/113dec0f-64c0-4f7e-b64f-30362d94f29a)

- 시간 단위로 window를 생성하여 특정 시각마다 고정된 요청을 처리할 수 있게 하는 알고리즘
쉽게 설명하면 위 사진은 1분에 3개의 요청을 처리할 수 있다
- 만약 window에 허용할 수 있는 요청수를 넘어선다면 해당 요청은 버려진다
- 단점 - 설계한 트래픽보다 많이 들어올 수 있다
    - 원래 예상한 이상적인 트래픽은 1시간마다 요청 4개를 처리하는 것이지만
    13시 전 후로 4개의 요청이 들어오게 된다면 순간적으로 1시간에 8개를 처리하게 된다.

![image](https://github.com/user-attachments/assets/62b655c2-fe43-421f-9628-474fe034f627)

## 6. Sliding Window Logging 알고리즘

![image](https://github.com/user-attachments/assets/c4719f70-c115-41dd-86f4-b6270f1c6fae)

![image](https://github.com/user-attachments/assets/f4cf40c8-6f12-4fa8-a3d0-9c7938898a01)

![image](https://github.com/user-attachments/assets/8fe7c4e6-e749-4d2a-829f-abb9a7209625)

- Fixed Window Counter의 문제점이 원래 설계한 처리율보다 더 높을 수 있다는 점인데, 타임스탬프를 추적하는 Sliding Window Counter 알고리즘으로 개선해서 문제를 해결함
- 사진 처리 과정 (* 윈도우 안에 2개의 요청만 처리할 수 있음)
    1. 0:01 요청이 처음 들어오게 되면 타임스탬프를 저장하고 요청을 허용한다
    2. 이후 0:15 요청이 들어오면 [-0:45 ~ 0:15) 사이의 요청은 1개이므로 타임스탬프를 저장하고 요청을 허용한다
    3. 이후 0:55 요청이 들어왔는데 [-0:05 ~ 0:55) 사이의 요청은 2개이므로 타임스탬프만 저장하고, 0:55 요청을 거부한다
    4. 이후 1:27 요청이 들어오면 [0:27 ~ 1:27) 사이의 요청은 존재하지 않으므로 허용할 수 있다
    이때 타임스탬프 로그에 0:01, 0:15가 있으므로 해당 로그 제거 후, 1:27 타임스탬프를 저장하고 요청을 허용한다
    5. 1:55 ~ 2:27 사이의 요청이 들어오면 만료된 로그인 0:55를 삭제하고, 요청 타임스탬프를 저장한 뒤 요청을 허용한다
- 장점 = 정교한 처리율 제한이 가능해진다
- 단점 = 실제 요청은 이것보다 많이 들어올 것이고, 유저마다 / API마다 타임스탬프가 저장되어서 적재하는 데이터가 많아진다

## 7. Sliding Window Counting 알고리즘

Fixed Window Counting + Sliding Window Logging을 합친 알고리즘

![image](https://github.com/user-attachments/assets/b3bd20dc-979f-490d-b6e6-8ab019b16657)

구현 방법은 두 가지가 있는데 하나만 설명함

- 현재 윈도에 들어오는 요청 수 = (현재 1분 간의 요청 수) + (직전 1분 간의 요청 수 * 직전 1분에서 이동 윈도가 차지하는 비율)
- 예시 사진 설명 (* 처리율 제한 = 1분에 7개의 요청까지 허용)
    - 공식을 사용하면 3 + (5 * 0.7) = 6.5개가 현재 윈도우에 들어있다 (소수점 내림, 반올림은 정책에 따라 달라짐)
    - 1분에 7개의 요청 처리가 가능하므로 최근에 들어온 3개의 요청이 모두 들어올 수 있다
    하지만 이후에 바로 요청이 들어오면 Rate Limit에 걸려서 요청이 거부된다
- 장점
    - Sliding Window Logging의 문제점인 메모리 문제를 개선했다
    - 짧은 시간에 몰리는 트래픽에도 잘 대응할 수 있다
- 단점
    - 직전 1분의 요청은 추정치로 게산하기 때문에 정확하지 않은 값이 나오는데, 심각한 문제는 아니다
    (CloudFlare에서 실험해보니 40억개 요청중에 예상을 넘어선 허용/거부 요청은 0.003% = 12만개임)

## 8. 분산 환경에서의 Rate Limit 구현 방법

단일 서버에서는 Rate Limit 구현이 쉽지만, 여러대의 서버가 존재한다면 경쟁 조건, 동기화 문제를 고려해야함

### [1] 경쟁 조건

![image](https://github.com/user-attachments/assets/cf3c4b71-6492-4100-bdf4-d2872bab2595)

- 처리율 제한을 할 때 read - modify - write 문제가 발생한다 (사진의 기대값은 2가 되어야함)
- 해결책은 락을 거는 방식이 있는데, 락은 성능을 저하시켜서 두가지 대안 방법이 존재한다
    - 루아 스크립트 (트랜잭션이랑 똑같이 원자적으로 실행하게 해줌)
    - 정렬 집합 활용해 타임스탬프를 관리함
        - 요청이 들어올 때마다 타임스탬프를 업데이트하는 과정을 Redis MULTI … EXEC 명령어를 사용해 원자적으로 처리할 수 있도록 함

### [2] 동기화 문제

사용자가 매우 많은 서비스라 Rate Limit도 여러개를 둔다면 정보를 동기화 시키는 문제도 발생함

단순한 방법은 Sticky Session 방식으로 사용할 수 있지만, 추천하지 않는 방법이라 레디스 같은 중앙 집중형 데이터베이스를 사용하는걸 권장한다

### [3] 성능 최적화

만약 글로벌 서비스를 운영하게 된다면 요청은 유럽에서 오는데, Rate Limit는 한국에만 있다면 처리율 제한에 걸리는 요청인지 확인하는데만 오랜 시간이 걸릴 것이다. 그래서 Rate Limit도 여러개를 배치할 수 있다.

지리적 문제를 해결하기 위해 다양한 나라에 엣지 서버를 둘 수 있는데, 엣지 서버를 두게 되면 데이터 동기화 문제가 발생하게 된다.

데이터 동기화 문제는 최종 일관성 모델을 사용하는 것이다.

일관성 모델 종류

- 강한 일관성 모델: 모든 읽기 요청이 직전의 모든 쓰기 결과를 반영해야한다
- 약한 일관성 모델: 모든 읽기 요청이 직전의 모든 쓰기 결과를 반영하지 않을 수 있다
- 최종 일관성 모델: 모든 읽기 요청이 직전의 모든 쓰기 결과를 반영하지 않을 수 있지만, 충분한 시간이 지나면 데이터 일관성이 보장된다
