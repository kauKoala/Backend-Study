### 1. 맵리듀스의 코드적 단점

- 맵리듀스를 통해 작업을 여러개 돌릴수록 작성할 코드가 많아짐
(3개의 맵리듀스 작업을 하는데, 총 수백줄의 코드로 각각의 맵리듀스를 세팅해야함)
- 복잡한 쿼리가 필요할 경우, 이 역시 코드가 복잡해진다.
- 실시간 스트리밍 처리가 어렵다 (실시간 데이터)

ex) 특정 텍스트 파일에서 가장 많이 언급된 단어 개수 구하기

SQL로 작업할 경우, 굉장히 쉽지만, 맵리듀스는 2개의 작업을 거쳐야함

작업 1) wordcount를 실행

작업 2) 작업 1의 결과에서 가장 많이 카운트된 단어를 찾는 작업 실행

### 2. 맵리듀스의 성능적 단점

Disk IO가 많이 일어나서 많이 느리다.

ex) 특정 데이터를 읽어와 재가공하고, 다시 결과를 저장하는 상황

1) Map에서 디스크에 있는 데이터를 읽어온다. (DISK IO 발생)

2) 데이터를 처리하며 중간 작업을 디스크에 저장한다 (DISK IO 발생)

3) Reduce가 중간 작업에 있는 디스크를 읽어온다 (DISK IO 발생)

4) 최종 결과를 디스크에 저장한다 (DISK IO 발생)

[실험]

wordcount 예제를 돌리는 것만 하더라도 큰 리소스가 발생한다.

파이썬의 경우 실행하고, 결과물을 보는데 1초도 안걸리지만, 하둡의 경우 5초 정도의 시간이 걸림

그리고 ec2.nano는 스왑메모리를 최대한 적용해도 바로 ec2가 터짐

- 맵리듀스의 단점을 보완하기 위해 나온 것이 스파크 -

### 3. 스파크 소개

![image](https://github.com/kauKoala/Backend-Study/assets/79046106/daa36670-a079-47cd-9290-3561204dab83)

[코드]

맵리듀스는 자바만 가능하지만, 스파크는 파이썬, 자바, 스칼라를 사용할 수 있다

[성능]

맵리듀스는 처음에 디스크에 있는 데이터를 읽어오고, 최종 데이터를 디스크에 저장하는건 당연한 일임

하지만 중간과정의 작업물도 전부 디스크에 기록을 하기 때문에 성능이 떨어지는 이슈가 존재했음

이런 문제를 해결하기 위해 스파크는 중간에 메모리에 저장하는 시스템을 두어서 빠른 처리를 할 수 있도록 만들어줌

메모리를 사용하기 때문에 연산속도도 빠르고, 캐싱도 된다.

### 4. Resilient Distribution DataSet (RDD)

회복성 있는 분산 데이터셋 (= 여러 분산 노드에 걸쳐서 저장함)

스파크 내에 저장된 데이터셋으로 Immutable함 (데이터 변경시 새로운 데이터셋을 만들어야함)

RDD는 2가지 종류의 연산만 지원한다.

1) Transformation

RDD를 사용하여 새로운 RDD를 만들어 내는 작업 (= 데이터를 가공하여 새로운 데이터를 만들어냄)

2) Action

RDD의 결과물을 생성해내는 것

ex) 학생 정보 테이블에서 각 학년의 학생 수를 구할 때, 데이터를 가공하는건 Transformation, 마지막에 결과물을 보여주는건 Action임

### 5. Lazy Evaluation

Spark는 Lazy Evaluation을 통해 더욱 성능 향상을 만들어냄 (JPA Lazy Loading과 비슷함)

Transformation을 실행할 때마다 바로바로 연산을 하는 것은 효율적이지 않음

그래서 Action을 할 때가 되서야 Transformation 작업을 실행함

이 경우 자체적인 최적화 과정을 거칠 수 있음

ex) RDD1 → RDD2 → RDD3 → …. → RDD7을 하여 결과물을 내는데, RDD1 → RDD6까지 Transformation 작업을 하지 않고 있다가, Action 연산을 하는 RDD7이 실행된다는걸 확인하고 나서야 RDD1부터 작업을 시작함

### 6. Spark Dataframe, Spark SQL

Spark로만 코딩을 할 때, 데이터의 과정을 생각하면서 코딩해야했음 (= 명령어가 직관적이지 않음)
RDD는 low level이라고 부르고, Dataframe, SQL을 통해 더 쉽게 코딩할 수 있도록함

Spark SQL은 SQL문법을 사용하기 때문에 제일 많은 사용자가 사용하고 있음
